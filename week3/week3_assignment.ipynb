{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from common.functions import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.Softmax 함수 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    ## 2차원인 경우와 1차원인 경우로 나누어서 계산\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis = 0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis = 0)\n",
    "        return y.T\n",
    "    \n",
    "    x = x - np.max(x)\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3층 신경망 구현(p.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) def init_network()에 가중치와 편향을 저장하도록 network 딕셔너리를 이용하여 표현하세요. 가중치는 임의의 숫자를 넣어주세요. 함수의 원형은 아래와 같고, network를 반환하도록 설계하세요.(return network)\n",
    "\n",
    "#교재\n",
    "\"\"\" \n",
    "def init_network(): \n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
    "    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "    return network\n",
    "\"\"\"\n",
    "\n",
    "def init_network(): ## 가중치와 편향 저장\n",
    "    network = {}\n",
    "    network['W1'] = np.random.randn(2, 2) ## 입력층 to 첫번째 은닉층 가중치\n",
    "    network['b1'] = np.random.randn(2) ## 첫번째 은닉층(h1, h2)에 들어가는 편향 2개\n",
    "    network['W2'] = np.random.randn(2, 3) ## 첫번째 은닉층 to 두번째 은닉층 가중치\n",
    "    network['b2'] = np.random.randn(3) ## 두번째 은닉층(s1, s2, s3)에 들어가는 가중치\n",
    "    network['W3'] = np.random.randn(3, 3) ## 두번째 은닉층 to 출력층 가중치\n",
    "    network['b3'] = np.random.randn(3) ## 출력층에 들어가는 가중치\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) def forward(network, x)에서 입력 신호를 출력으로 변환하는 처리 과정을 구현해 보려고 합니다. 1)에서 반환한 network를 forward의 입력 인수로 넣는 것을 고려해서 구현하세요. 이 함수의 출력값은 y입니다.(return y)\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = identity_function(a3)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.46195347  2.14950918 -1.1838769 ]\n"
     ]
    }
   ],
   "source": [
    "# 3) 이제 main 함수에서 아래와 같은 형태를 실행하고, 값의 형태가 올바른 지 확인하세요.\n",
    "network = init_network()\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(network, x)  # [ 0.31682708  0.69627909]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. MNIST 데이터를 활용하여 신경망의 추론처리 과정을 구현하기 (p.96 ~ p.105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# 1) 아래 코드를 실행하여서 라이브러리를 import 하세요\n",
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train),(x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) 이제부터 MNIST 데이터셋을 가지고 추론을 수행하는 신경망을 구현해 보려고 합니다. 아래 세 가지 함수에 조건에 맞게 구현하세요.\n",
    "\n",
    "#a. def get_data() : mnist.py 의 load_mnist 함수를 이용해서 데이터를 불러온 후, 테스트 데이터를 반환하도록 구현하세요. (return x_test, t_test)\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = \\\n",
    "        load_mnist(flatten=True, normalize=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "#b. def init_network() : 기존에 다운받은 mnist.pkl 에는 학습이 완료된 가중치 매개변수가 들어 있습니다. Mnist.pkl 를 불러온 다음에 가중치 매개변수를 반환하도록 구현하세요. (return network)\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "        # 학습된 가중치 매개변수가 담긴 파일\n",
    "        # 학습 없이 바로 추론을 수행\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "#c. def predict(network, x) : b 에서 불러온 가중치 매개변수와 a 에서 불러온 데이터를 활용해서 연산을 진행한 후, 각 레이블의 확률을 반환하도록 구현하세요. 해당 신경망의 구조는 아래의 형태입니다. (return y)\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3) #없이해도 결과 동일\n",
    "    return y\n",
    "\n",
    "#d. def init_network2() : b 에서와 다르게, Q3 에서 구현했던 3 층 신경망과 비슷한 형태로 network 를 만들어서 반환하도록 구현하세요. 가중치는 무작위로 초기화를 시켜주시면 됩니다. (return network)\n",
    "def init_network2():\n",
    "    network = {}\n",
    "    network['W1'] = np.random.ranf((784, 50))\n",
    "    network['b1'] = np.random.ranf((50,))\n",
    "    network['W2'] = np.random.ranf((50, 100))\n",
    "    network['b2'] = np.random.ranf((100,))\n",
    "    network['W3'] = np.random.ranf((100, 10))\n",
    "    network['b3'] = np.random.ranf((10,))\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle파일의 Accuracy:0.9352\n",
      "랜덤 가중치 Accuracy:0.0974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n- 사전 훈련된 가중치를 사용한것은 딥러닝과정을 통해 구현할 목표(마지막 가중치)\\n- 랜덤값을 사용한 것은 역전파과정을 진행하기 전 처음 가중치\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e. b 에서 구현한 네트워크와 d 에서 구현한 네트워크와의 정확도를 비교해보고, 어떤 점에서 차이가 있었는 지를 추론해 보세요.\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "accuracy_cnt = 0 #맞힌 개수\n",
    "batch_size = 100\n",
    "\n",
    "# pickle파일의 가중치\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y)  # 확률이 가장 높은 원소의 인덱스를 얻는다.(마지막 softmax된 확률 중)\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "print(\"pickle파일의 Accuracy:\" + str(float(accuracy_cnt) / len(x)))  # Accuracy:0.9352\n",
    "\n",
    "# 랜덤 가중치\n",
    "network = init_network2()\n",
    "accuracy_cnt = 0 #초기화\n",
    "\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y)  # 확률이 가장 높은 원소의 인덱스를 얻는다.(마지막 softmax된 확률 중)\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "print(\"랜덤 가중치 Accuracy:\" + str(float(accuracy_cnt) / len(x)))\n",
    "\n",
    "\"\"\"\n",
    "- 사전 훈련된 가중치를 사용한것은 딥러닝과정을 통해 구현할 목표(마지막 가중치)\n",
    "- 랜덤값을 사용한 것은 역전파과정을 진행하기 전 처음 가중치\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 이전에는 데이터 하나씩 계산을 해서 결과를 출력하는 과정이었습니다. 이제는 데이터를 여러 개 이상 사용해서 한 번에 연산을 진행해보려고 합니다. 한번에 100 개씩 처리할 수 있도록 main 에서 구현하세요. (p.104)\n",
    "def main():\n",
    "    x, t = get_data()\n",
    "    network = init_network()\n",
    "    accuracy_cnt = 0 #맞힌 개수\n",
    "\n",
    "    batch_size = 100\n",
    "\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        y_batch = predict(network, x_batch)\n",
    "        p = np.argmax(y_batch, axis=1) #마지막 10개를 sofamax통과시킨 것들 중 최대값(확률)\n",
    "        accuracy_cnt += np.sum(p == t[i:i+batch_size]) #제일높아보이는 확률과, 라벨값이 일치하는 개수\n",
    "\n",
    "    print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))  # Accuracy:0.9352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
